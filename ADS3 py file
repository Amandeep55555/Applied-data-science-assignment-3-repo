# Necessary Libraries And Fitting

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# Read CSV
file_name = 'API_EN.ATM.CO2E.PC_DS2_en_csv_v2_5358914.csv'
df = pd.read_csv(file_name, skiprows=4)

# Including Functions From Class Practical

def scaler(df):
    """ Expects a dataframe and normalises all 
        columnsto the 0-1 range. It also returns 
        dataframes with minimum and maximum for
        transforming the cluster centres"""

    # Uses the pandas methods
    df_min = df.min()
    df_max = df.max()

    df = (df-df_min) / (df_max - df_min)

    return df, df_min, df_max


def backscale(arr, df_min, df_max):
    """ Expects an array of normalised cluster centres and scales
        it back. Returns numpy array.  """

    # convert to dataframe to enable pandas operations
    minima = df_min.to_numpy()
    maxima = df_max.to_numpy()

    # loop over the "columns" of the numpy array
    for i in range(len(minima)):
        arr[:, i] = arr[:, i] * (maxima[i] - minima[i]) + minima[i]

    return arr

# Selecting the columns to be used for clustering
columns_to_use = [str(year) for year in range(1990, 2020)]
df_years = df[['Country Name', 'Country Code'] + columns_to_use]

# Fill missing values with the mean
df_years = df_years.fillna(df_years.mean())

# Normalize the data
df_norm, df_min, df_max = scaler(df_years[columns_to_use])

# Find the optimal number of clusters using the elbow method
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)
    kmeans.fit(df_norm)
    wcss.append(kmeans.inertia_)
plt.plot(range(1, 11), wcss)
plt.title('Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

# Apply the KMeans clustering algorithm
optimal_clusters = 3
kmeans = KMeans(n_clusters=optimal_clusters, init='k-means++', max_iter=300, n_init=10, random_state=0)
df_years['Cluster'] = kmeans.fit_predict(df_norm)

# Plot the clustering results
plt.figure(figsize=(12, 8))
for i in range(optimal_clusters):
    plt.scatter(df_years[df_years['Cluster'] == i].index, df_years[df_years['Cluster'] == i]['2019'], label=f'Cluster {i}')

# Plot the cluster centers
cluster_centers = backscale(kmeans.cluster_centers_, df_min, df_max)
for i in range(optimal_clusters):
    plt.scatter(len(df_years), cluster_centers[i, -1], marker='*', s=150, c='black', label=f'Cluster Center {i}')

plt.title('CO2 Emissions Clustering')
plt.xlabel('Country Index')
plt.ylabel('CO2 Emissions (metric tons per capita) in 2019')
plt.legend()
plt.show()

# Display countries in each cluster
for i in range(optimal_clusters):
    cluster_countries = df_years[df_years['Cluster'] == i][['Country Name', 'Country Code']]
    print(f'Countries in Cluster {i}:')
    print(cluster_countries)
    print()

# Fitting Into A Linear Model
import numpy as np
from scipy.optimize import curve_fit

def linear_model(x, a, b):
    return a * x + b

country = 'United States'

# Extract data for the selected country
country_data = df_years.loc[df_years['Country Name'] == country][columns_to_use].values[0]
x_data = np.array(range(1990, 2020))
y_data = country_data

# Fit the linear model
popt, pcov = curve_fit(linear_model, x_data, y_data)

def err_ranges(popt, pcov, x):
    perr = np.sqrt(np.diag(pcov))
    y = linear_model(x, *popt)
    lower = linear_model(x, *(popt - perr))
    upper = linear_model(x, *(popt + perr))
    return y, lower, upper

# Predict values and confidence ranges for the future
x_future = np.array(range(1990, 2031))
y_future, lower_future, upper_future = err_ranges(popt, pcov, x_future)

# Plot the results
plt.figure(figsize=(12, 6))
plt.plot(x_data, y_data, 'o', label='Data')
plt.plot(x_future, y_future, '-', label='Best Fit')
plt.fill_between(x_future, lower_future, upper_future, alpha=0.3, label='Confidence Range')
plt.xlabel('Year')
plt.ylabel('CO2 Emissions (metric tons per capita)')
plt.title(f'{country} CO2 Emissions Fitting')
plt.legend()
plt.show()

